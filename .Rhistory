library(xgboost)
eda_data <-
data
eda_data <-
eda_data %>%
select(-"EmployeeCount")
apply(is.na(eda_data), 2, sum)
glimpse(eda_data)
str(eda_data)
# RandomForest
idx <- createDataPartition(eda_data$Attrition,
p = 0.7,
list = FALSE,
times = 1)
rfdata_train <- eda_data[ idx,]
rfdata_test  <- eda_data[-idx,]
## 2.2. 모형적합 ------
fit_ctrl <- trainControl(method = "repeatedcv", number = 3, repeats = 2)
data_rf <- train(Attrition ~ .,
data = rfdata_train,
method = "rf",
preProcess = c("scale", "center"),
trControl = fit_ctrl,
verbose = FALSE)
## 2.3. 모형성능평가 ------
rftest_predict <- predict(data_rf, rfdata_test)
confusionMatrix(rftest_predict, rfdata_test$Attrition)
# 3. 모형 설명 -----
## 3.1. 중요변수 추출 -----
data_rf_imp <- varImp(data_rf, scale = TRUE)
(top_ten_variable_v <- data_rf_imp$importance %>%
as.data.frame() %>%
rownames_to_column(var="variable") %>%
filter(!(variable == "EmployeeNumber")) %>%
top_n(10, Overall) %>%
pull(variable))
rfTopPlot <-
data_rf_imp$importance %>%
as.data.frame() %>%
rownames_to_column(var="variable") %>%
ggplot(aes(x = reorder(variable, Overall), y = Overall)) +
geom_bar(stat = "identity", fill = "#1F77B4", alpha = 0.8) +
coord_flip() +
labs(y="중요도", x="요소") +
theme_minimal(base_family="NanumGothic")
rfROC<-
plot.roc (as.numeric(rfdata_test$Attrition), as.numeric(rftest_predict),lwd=2, type="b", print.auc=TRUE,col ="steelblue")
#XGBdata
# factor 전처리 : XGB 분석을 위해 종속변수 값을 chr-factor로 변경 (1:0 시 에러)
xgb_data <- eda_data %>%
mutate(Attrition = ifelse(Attrition == 1,"Yes","No"))
xgb_data$Attrition <-
as.factor(xgb_data$Attrition)
set.seed(123)
#xgbData <- eda_data
indexes <- sample(1:nrow(xgb_data), size=0.7*nrow(xgb_data))
xgbdata_train <- xgb_data[indexes,]
xgbdata_test <- xgb_data[-indexes,]
formula = Attrition~.
#levels(eda_data$Attrition) <- make.names(levels(factor(eda_data$Attrition)))
fitControl <- trainControl(method="cv", number = 3, classProbs = TRUE)
xgbGrid <- expand.grid(nrounds = 50,
max_depth = 12,
eta = .03,
gamma = 0.01,
colsample_bytree = .7,
min_child_weight = 1,
subsample = 0.9
)
xgbModel <- train(formula, data = xgbdata_train,
method = "xgbTree"
,trControl = fitControl
, verbose=0
, maximize=FALSE
,tuneGrid = xgbGrid
)
importance <- varImp(xgbModel)
varImportance <- data.frame(Variables = row.names(importance[[1]]),
Importance = round(importance[[1]]$Overall,2))
rankImportance <- varImportance %>%
mutate(Rank = paste0('#',dense_rank(desc(Importance))))
# ggplot(rankImportance, aes(x = reorder(Variables, Importance),
#                            y = Importance)) +
#   geom_bar(stat='identity',colour="white", fill = "lightgreen") +
#   geom_text(aes(x = Variables, y = 1, label = Rank),
#             hjust=0, vjust=.5, size = 4, colour = 'black',
#             fontface = 'bold') +
#   labs(x = 'Variables', title = 'Relative Variable Importance') +
#   coord_flip() +
#   theme_minimal()
xgbTopPlot <-
rankImportance %>%
as.data.frame() %>%
filter(!(Variables == "EmployeeNumber")) %>%
#rownames_to_column(var="Variable") %>%
ggplot(aes(x = reorder(Variables, Importance), y = Importance)) +
geom_bar(stat = "identity", fill = "seagreen", alpha = 0.8) +
coord_flip() +
labs(y="중요도", x="요소") +
theme_minimal(base_family="NanumGothic")
xgbPredict <- predict(xgbModel,xgbdata_test)
confusionMatrix(xgbPredict, xgbdata_test$Attrition)
xgbROC<-
plot.roc (as.numeric(xgbdata_test$Attrition), as.numeric(xgbPredict),lwd=2, type="b", print.auc=TRUE,col ="seagreen")
# eda_data$Attrition <- as.integer(as.character(eda_data$Attrition)=="Yes")
# eda_data$Attrition <-as.factor(eda_data$Attrition)
# RandomForest로 모델링...
# plot(rftest_predict)
# plot(xgbPredict)
rsconnect::showLogs()
runApp('hrda')
result.EmployeeNumber
View(result)
x.scaled
runApp('hrda')
runApp('hrda')
runApp('hrda')
data[raw$Attrition == input$Attrition]
data[raw$Attrition]
data[raw$Attrition == 5]
data[raw$Attrition == "Yes"]
raw[raw$Attrition == "Yes"]
View(data)
View(raw)
raw[raw$Attrition == "Yes"]
raw$Attrition == "Yes"
raw[raw$Attrition == "Yes",]
runApp('hrda')
runApp('hrda')
runApp('hrda')
rsconnect::showLogs()
getwd()
runApp('hrda')
getwd()
setwd("twd()
[1] "/Users/yelahj/Project/hrdaapp/hrda/hrda")
)
))
setW)D)
()
setwd("/Users/yelahj/Project/hrdaapp/hrda/hrda")
runApp()
runApp()
runApp()
rsconnect::showLogs()
runApp()
runApp()
runApp()
runApp()
rsconnect::showLogs()
runApp()
# GENDER 변경..
rfdata_train$Gender <-
as.numeric(rfdata_train$Gender)
rfdata_test$Gender <-
as.numeric(rfdata_test$Gender)
#### RANDOMFOREST FIT
rand_forest(trees=100, mode='classification') %>%
set_engine('randomForest') %>%
fit(Attrition~
+ Age
+ DistanceFromHome
+ Education
+ EducationField
+ EnvironmentSatisfaction
+ JobInvolvement
+ JobRole
+ JobSatisfaction
+ MaritalStatus
+ MonthlyIncome
+ NumCompaniesWorked
+ PercentSalaryHike
+ RelationshipSatisfaction
+ TotalWorkingYears
+ TrainingTimesLastYear
+ WorkLifeBalance
+ YearsAtCompany
+ YearsInCurrentRole
+ YearsSinceLastPromotion
+ YearsWithCurrManager
+ MonthlyLeaves
+ OverTimeHours
, data=rfdata_train) -> data_rg
result =
data_rg %>%
predict(rfdata_test, type="prob") %>%
bind_cols(rfdata_test)
# bind해서 test한 데이터와 train한 데이터 비교
data_rg %>%
predict(rfdata_test) %>%
bind_cols(rfdata_test)
data_rg %>%
predict(rfdata_test) %>%
bind_cols(rfdata_test) %>%
metrics(truth=Attrition, estimate=.pred_class)
# 시험데이터 예측
x.scaled <- result %>%
select(top_ten_variable_v)
shiny::runApp('hrda')
runApp('hrda')
runApp('hrda')
runApp('hrda')
runApp('hrda')
runApp('hrda')
runApp('hrda')
shiny::runApp('hrda')
runApp('hrda')
# 1. IBM HR Analysis on Kaggle에서 제공하는 IBM 데이터를 활용하여 데이터를 분석합니다.
raw <- read_csv("data/dataset.csv")
raw <-
raw %>%
mutate(Department = case_when(
Department == "Research & Development" ~ "Audit",
Department == "Sales" ~ "Tax",
Department == "Human Resources" ~ "CS&DA"
)) %>%
mutate(DistanceFromHome = case_when(
DistanceFromHome %in%  1:10  ~ "30분미만",
DistanceFromHome %in%  11:20 ~ "1시간미만",
DistanceFromHome %in%  21:30 ~ "1시간이상"
)) %>%
mutate(EducationField = case_when(
EducationField == "Marketing" ~ "인문학",
EducationField == "Life Sciences" ~ "기술공학",
EducationField == "Medical" ~ "상경계",
EducationField == "Technical Degree" ~ "자연과학",
EducationField == "Human Resources" ~ "예체능",
EducationField == "Other" ~ "기타"
))  %>%
mutate(JobRole = case_when(
JobRole == "Sales Executive" ~ "감사직",
JobRole == "Research Scientist" ~ "컨설팅직",
JobRole == "Healthcare Representative" ~ "투자자문직",
JobRole == "Laboratory Technician" ~ "기술컨설팅직",
JobRole == "Manufacturing Director" ~ "세무직",
JobRole == "Human Resources" ~ "사무직",
JobRole == "Manager" ~ "R&D",
JobRole == "Research Director" ~ "기술직",
JobRole == "Sales Representative" ~ "영업직"
))
#### RANDOMFOREST FIT
rand_forest(trees=100, mode='classification') %>%
set_engine('randomForest') %>%
fit(Attrition~
+ Age
+ DistanceFromHome
+ Education
+ EducationField
+ EnvironmentSatisfaction
+ JobInvolvement
+ JobRole
+ JobSatisfaction
+ MaritalStatus
+ MonthlyIncome
+ NumCompaniesWorked
+ PercentSalaryHike
+ RelationshipSatisfaction
+ TotalWorkingYears
+ TrainingTimesLastYear
+ WorkLifeBalance
+ YearsAtCompany
+ YearsInCurrentRole
+ YearsSinceLastPromotion
+ YearsWithCurrManager
+ MonthlyLeaves
+ OverTimeHours
, data=rfdata_train) -> data_rg
result =
data_rg %>%
predict(rfdata_test, type="prob") %>%
bind_cols(rfdata_test)
result
# bind해서 test한 데이터와 train한 데이터 비교
data_rg %>%
predict(rfdata_test) %>%
bind_cols(rfdata_test)
data_rg %>%
predict(rfdata_test) %>%
bind_cols(rfdata_test) %>%
metrics(truth=Attrition, estimate=.pred_class)
rand_forest(trees=200, mode='classification') %>%
set_engine('randomForest') %>%
fit(Attrition~
+ Age
+ DistanceFromHome
+ Education
+ EducationField
+ EnvironmentSatisfaction
+ JobInvolvement
+ JobRole
+ JobSatisfaction
+ MaritalStatus
+ MonthlyIncome
+ NumCompaniesWorked
+ PercentSalaryHike
+ RelationshipSatisfaction
+ TotalWorkingYears
+ TrainingTimesLastYear
+ WorkLifeBalance
+ YearsAtCompany
+ YearsInCurrentRole
+ YearsSinceLastPromotion
+ YearsWithCurrManager
+ MonthlyLeaves
+ OverTimeHours
, data=rfdata_train) -> data_rg
result =
data_rg %>%
predict(rfdata_test, type="prob") %>%
bind_cols(rfdata_test)
# bind해서 test한 데이터와 train한 데이터 비교
data_rg %>%
predict(rfdata_test) %>%
bind_cols(rfdata_test)
# 성능측정
data_rg %>%
predict(rfdata_test) %>%
bind_cols(rfdata_test) %>%
metrics(truth=Attrition, estimate=.pred_class)
#### RANDOMFOREST FIT
rand_forest(trees=200, mode='classification') %>%
set_engine('randomForest') %>%
fit(Attrition~
+ Age
+ DistanceFromHome
+ Education
+ EducationField
+ EnvironmentSatisfaction
+ JobInvolvement
+ JobRole
+ JobSatisfaction
+ MaritalStatus
+ MonthlyIncome
+ NumCompaniesWorked
+ PercentSalaryHike
+ RelationshipSatisfaction
+ TotalWorkingYears
+ TrainingTimesLastYear
+ WorkLifeBalance
+ YearsAtCompany
+ YearsInCurrentRole
+ YearsSinceLastPromotion
+ YearsWithCurrManager
+ MonthlyLeaves
+ OverTimeHours
, data=rfdata_train) -> data_rg
#### RANDOMFOREST FIT
rand_forest(trees=200, mode='classification') %>%
set_engine('randomForest') %>%
fit(Attrition~
+ Age
+ DistanceFromHome
+ Education
+ EducationField
+ EnvironmentSatisfaction
+ JobInvolvement
+ JobRole
+ JobSatisfaction
+ MaritalStatus
+ MonthlyIncome
+ NumCompaniesWorked
+ PercentSalaryHike
+ RelationshipSatisfaction
+ TotalWorkingYears
+ TrainingTimesLastYear
+ WorkLifeBalance
+ YearsAtCompany
+ YearsInCurrentRole
+ YearsSinceLastPromotion
+ YearsWithCurrManager
+ MonthlyLeaves
+ OverTimeHours
, data=rfdata_train) -> data_rg
#### RANDOMFOREST FIT
rand_forest(trees=200, mode='classification') %>%
set_engine('randomForest') %>%
fit(Attrition~
+ Age
+ DistanceFromHome
+ Education
+ EducationField
+ EnvironmentSatisfaction
+ JobInvolvement
+ JobRole
+ JobSatisfaction
+ MaritalStatus
+ MonthlyIncome
+ NumCompaniesWorked
+ PercentSalaryHike
+ RelationshipSatisfaction
+ TotalWorkingYears
+ TrainingTimesLastYear
+ WorkLifeBalance
+ YearsAtCompany
+ YearsInCurrentRole
+ YearsSinceLastPromotion
+ YearsWithCurrManager
+ MonthlyLeaves
+ OverTimeHours
, data=rfdata_train) -> data_rg
#### RANDOMFOREST FIT
rand_forest(trees=200, mode='classification') %>%
set_engine('randomForest') %>%
fit(Attrition~
+ Age
+ DistanceFromHome
+ Education
+ EducationField
+ EnvironmentSatisfaction
+ JobInvolvement
+ JobRole
+ JobSatisfaction
+ MaritalStatus
+ MonthlyIncome
+ NumCompaniesWorked
+ PercentSalaryHike
+ RelationshipSatisfaction
+ TotalWorkingYears
+ TrainingTimesLastYear
+ WorkLifeBalance
+ YearsAtCompany
+ YearsInCurrentRole
+ YearsSinceLastPromotion
+ YearsWithCurrManager
+ MonthlyLeaves
+ OverTimeHours
, data=rfdata_train) -> data_rg
#### RANDOMFOREST FIT
rand_forest(trees=200, mode='classification') %>%
set_engine('randomForest') %>%
fit(Attrition~
+ Age
+ DistanceFromHome
+ Education
+ EducationField
+ EnvironmentSatisfaction
+ JobInvolvement
+ JobRole
+ JobSatisfaction
+ MaritalStatus
+ MonthlyIncome
+ NumCompaniesWorked
+ PercentSalaryHike
+ RelationshipSatisfaction
+ TotalWorkingYears
+ TrainingTimesLastYear
+ WorkLifeBalance
+ YearsAtCompany
+ YearsInCurrentRole
+ YearsSinceLastPromotion
+ YearsWithCurrManager
+ MonthlyLeaves
+ OverTimeHours
, data=rfdata_train) -> data_rg
# 성능측정
data_rg %>%
predict(rfdata_test) %>%
bind_cols(rfdata_test) %>%
metrics(truth=Attrition, estimate=.pred_class)
x.scaled <- data.frame(lapply(x.scaled, resc))
x.scaled <- data.frame(
lapply(x.scaled, resc),
result$EmployeeNumber
)
library(cond)
library(ggcorrplot)
rfdata_train$Gender <-
as.numeric(rfdata_train$Gender)
rfdata_train$Gender <-
as.numeric(rfdata_train$Gender)
rfdata_test$Gender <-
as.numeric(rfdata_test$Gender)
#### RANDOMFOREST FIT
rand_forest(trees=200, mode='classification') %>%
set_engine('randomForest') %>%
fit(Attrition~
+ Age
+ DistanceFromHome
+ Education
+ EducationField
+ EnvironmentSatisfaction
+ JobInvolvement
+ JobRole
+ JobSatisfaction
+ MaritalStatus
+ MonthlyIncome
+ NumCompaniesWorked
+ PercentSalaryHike
+ RelationshipSatisfaction
+ TotalWorkingYears
+ TrainingTimesLastYear
+ WorkLifeBalance
+ YearsAtCompany
+ YearsInCurrentRole
+ YearsSinceLastPromotion
+ YearsWithCurrManager
+ MonthlyLeaves
+ OverTimeHours
, data=rfdata_train) -> data_rg
result =
data_rg %>%
predict(rfdata_test, type="prob") %>%
bind_cols(rfdata_test)
data_rg %>%
predict(rfdata_test) %>%
bind_cols(rfdata_test)
data_rg %>%
predict(rfdata_test) %>%
bind_cols(rfdata_test) %>%
metrics(truth=Attrition, estimate=.pred_class)
x.scaled <- result %>%
select(top_ten_variable_v)
